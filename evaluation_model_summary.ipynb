{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "from model_function import *\n",
    "from model_utils import *\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as Fin\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "from torchdiffeq import odeint as odeint\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.empty_cache() \n",
    "import torch.optim as optim\n",
    "import random\n",
    "import logging\n",
    "logging.propagate = False \n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "import sys\n",
    "\n",
    "set_seed(42)\n",
    "cwd = os.getcwd()\n",
    "#data_path = {'z500':str(cwd) + '/era5_data/geopotential_500/*.nc','t850':str(cwd) + '/era5_data/temperature_850/*.nc'}\n",
    "SOLVERS = [\"dopri8\",\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams', 'fixed_adams',\"adaptive_heun\",\"euler\"]\n",
    "parser = argparse.ArgumentParser('ClimODE')\n",
    "\n",
    "solver = \"euler\"\n",
    "atol = 5e-3\n",
    "rtol = 5e-3\n",
    "step_size = None  # Optional fixed step size\n",
    "niters = 300\n",
    "scale = 0\n",
    "batch_size = 8\n",
    "spectral = 0  # Choices: [0, 1]\n",
    "lr = 0.0005\n",
    "weight_decay = 1e-5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "train_time_scale= slice('2006','2016')\n",
    "val_time_scale = slice('2016','2016')\n",
    "test_time_scale = slice('2017','2018')\n",
    "\n",
    "paths_to_data = [str(cwd) + '/era5_data/geopotential_500/*.nc',str(cwd) + '/era5_data/temperature_850/*.nc',str(cwd) + '/era5_data/2m_temperature/*.nc',str(cwd) + '/era5_data/10m_u_component_of_wind/*.nc',str(cwd) + '/era5_data/10m_v_component_of_wind/*.nc']\n",
    "\n",
    "num_years = len(range(2006,2016))\n",
    "\n",
    "\n",
    "class Climate_encoder_free_uncertain_summary(nn.Module): \n",
    "    \n",
    "    def __init__(self,num_channels,const_channels,out_types,method,use_att,use_err,use_pos):\n",
    "        super().__init__()\n",
    "        self.layers = [5,3,2]\n",
    "        self.hidden = [128,64,2*out_types]\n",
    "        input_channels = 30 + out_types*int(use_pos) + 34*(1-int(use_pos))\n",
    "        self.vel_f = Climate_ResNet_2D(input_channels,self.layers,self.hidden)\n",
    "\n",
    "        if use_att: \n",
    "            self.vel_att = Self_attn_conv(input_channels,10)\n",
    "            self.gamma = nn.Parameter(torch.tensor([0.1]))\n",
    "\n",
    "        self.scales = num_channels\n",
    "        self.const_channel = const_channels\n",
    "        \n",
    "        self.out_ch = out_types\n",
    "        self.past_samples = 0\n",
    "        self.const_info = 0\n",
    "        self.lat_map = 0\n",
    "        self.lon_map = 0\n",
    "        self.elev = 0\n",
    "        self.pos_emb = 0\n",
    "        self.elev_info_grad_x = 0\n",
    "        self.elev_info_grad_y = 0\n",
    "        self.method = method\n",
    "        err_in =  9 + out_types*int(use_pos) + 34*(1-int(use_pos))\n",
    "        if use_err: self.noise_net = Climate_ResNet_2D(err_in,[3,2,2],[128,64,2*out_types])\n",
    "        if use_pos: self.pos_enc = Climate_ResNet_2D(4,[2,1,1],[32,16,out_types])\n",
    "        self.att = use_att\n",
    "        self.err = use_err\n",
    "        self.pos = use_pos\n",
    "        self.pos_feat = 0\n",
    "        self.lsm =0 \n",
    "        self.oro =0 \n",
    "\n",
    "\n",
    "    def update_param(self, params):\n",
    "        self.past_samples = params[0]\n",
    "        self.const_info = params[1]\n",
    "        self.lat_map = params[2]\n",
    "        self.lon_map = params[3]\n",
    "\n",
    "    def pde(self,t,vs):\n",
    "\n",
    "        ds = vs[:,-self.out_ch:,:,:].view(-1,self.out_ch,vs.shape[2],vs.shape[3]).float()\n",
    "        v = vs[:,:2*self.out_ch,:,:].view(-1,2*self.out_ch,vs.shape[2],vs.shape[3]).float()\n",
    "        t_emb = ((t*100)%24).view(1,1,1,1).expand(ds.shape[0],1,ds.shape[2],ds.shape[3])\n",
    "        sin_t_emb = torch.sin(torch.pi*t_emb/12 - torch.pi/2)\n",
    "        cos_t_emb = torch.cos(torch.pi*t_emb/12 - torch.pi/2)\n",
    "        \n",
    "        sin_seas_emb = torch.sin(torch.pi*t_emb/(12*365) - torch.pi/2)\n",
    "        cos_seas_emb = torch.cos(torch.pi*t_emb/(12*365) - torch.pi/2)\n",
    "\n",
    "        day_emb = torch.cat([sin_t_emb,cos_t_emb],dim=1)\n",
    "        seas_emb = torch.cat([sin_seas_emb,cos_seas_emb],dim=1)\n",
    "        \n",
    "        ds_grad_x = torch.gradient(ds,dim=3)[0]\n",
    "        ds_grad_y = torch.gradient(ds,dim=2)[0]\n",
    "        nabla_u = torch.cat([ds_grad_x,ds_grad_y],dim=1)\n",
    "\n",
    "        if self.pos:\n",
    "            comb_rep = torch.cat([t_emb/24,day_emb,seas_emb,nabla_u,v,ds,self.pos_feat],dim=1)\n",
    "        else:\n",
    "            cos_lat_map,sin_lat_map = torch.cos(self.new_lat_map),torch.sin(self.new_lat_map)\n",
    "            cos_lon_map,sin_lon_map = torch.cos(self.new_lon_map),torch.sin(self.new_lon_map)\n",
    "            t_cyc_emb = torch.cat([day_emb,seas_emb],dim=1)\n",
    "            pos_feats = torch.cat([cos_lat_map,cos_lon_map,sin_lat_map,sin_lon_map,sin_lat_map*cos_lon_map,sin_lat_map*sin_lon_map],dim=1)\n",
    "            pos_time_ft = self.get_time_pos_embedding(t_cyc_emb,pos_feats)\n",
    "            comb_rep = torch.cat([t_emb/24,day_emb,seas_emb,nabla_u,v,ds,self.new_lat_map,self.new_lon_map,self.lsm,self.oro,pos_feats,pos_time_ft],dim=1)\n",
    "\n",
    "        if self.att: dv = self.vel_f(comb_rep) + self.gamma*self.vel_att(comb_rep)\n",
    "        else: dv = self.vel_f(comb_rep)\n",
    "        v_x = v[:,:self.out_ch,:,:].view(-1,self.out_ch,vs.shape[2],vs.shape[3]).float()\n",
    "        v_y = v[:,-self.out_ch:,:,:].view(-1,self.out_ch,vs.shape[2],vs.shape[3]).float()\n",
    "\n",
    "        adv1 = v_x*ds_grad_x + v_y*ds_grad_y\n",
    "        adv2 = ds*(torch.gradient(v_x,dim=3)[0] + torch.gradient(v_y,dim=2)[0] )\n",
    "        \n",
    "\n",
    "        ds = adv1 + adv2\n",
    "\n",
    "        dvs = torch.cat([dv,ds],1)\n",
    "        return dvs\n",
    "    \n",
    "\n",
    "    def get_time_pos_embedding(self,time_feats,pos_feats):\n",
    "        for idx in range(time_feats.shape[1]):\n",
    "            tf = time_feats[:,idx].unsqueeze(dim=1)*pos_feats\n",
    "            if idx == 0:\n",
    "                final_out = tf\n",
    "            else:\n",
    "                final_out = torch.cat([final_out,tf],dim=1)\n",
    "\n",
    "        return final_out\n",
    "\n",
    "    def noise_net_contrib(self,t,pos_enc,s_final,noise_net,H,W):\n",
    "\n",
    "        t_emb = (t%24).view(-1,1,1,1,1)\n",
    "        sin_t_emb = torch.sin(torch.pi*t_emb/12 - torch.pi/2).expand(len(s_final),s_final.shape[1],1,H,W)\n",
    "        cos_t_emb = torch.cos(torch.pi*t_emb/12 - torch.pi/2).expand(len(s_final),s_final.shape[1],1,H,W)\n",
    "        \n",
    "        sin_seas_emb = torch.sin(torch.pi*t_emb/(12*365)- torch.pi/2).expand(len(s_final),s_final.shape[1],1,H,W)\n",
    "        cos_seas_emb = torch.cos(torch.pi*t_emb/(12*365)- torch.pi/2).expand(len(s_final),s_final.shape[1],1,H,W)\n",
    "\n",
    "        pos_enc = pos_enc.expand(len(s_final),s_final.shape[1],-1,H,W).flatten(start_dim=0,end_dim=1)\n",
    "        t_cyc_emb = torch.cat([sin_t_emb,cos_t_emb,sin_seas_emb,cos_seas_emb],dim=2).flatten(start_dim=0,end_dim=1)\n",
    "\n",
    "        pos_time_ft = self.get_time_pos_embedding(t_cyc_emb,pos_enc[:,2:-2])\n",
    "\n",
    "        comb_rep = torch.cat([t_cyc_emb,s_final.flatten(start_dim=0,end_dim=1),pos_enc,pos_time_ft],dim=1)\n",
    "\n",
    "        final_out = noise_net(comb_rep).view(len(t),-1,2*self.out_ch,H,W)\n",
    "\n",
    "        mean = s_final + final_out[:,:,:self.out_ch]\n",
    "        std = nn.Softplus()(final_out[:,:,self.out_ch:])\n",
    "        \n",
    "        return mean,std\n",
    "\n",
    "\n",
    "    def forward(self, T=None, data=None, atol=0.1, rtol=0.1):\n",
    "        # if T is None:\n",
    "        #     T = torch.tensor([0.0, 1.0])  # Example time tensor\n",
    "        # if data is None:\n",
    "        #     data = torch.zeros(1, self.out_ch, 128, 128)  # Ensure 4D shape\n",
    "        print(type(self.past_samples))\n",
    "\n",
    "        H, W = self.past_samples.shape[2], self.past_samples.shape[3]\n",
    "        \n",
    "        # Debug the shapes\n",
    "        print(f\"Shape of self.past_samples: {self.past_samples.shape}\")\n",
    "        print(f\"Shape of data: {data.shape}\")\n",
    "\n",
    "        # Ensure batch size matches between self.past_samples and data\n",
    "        if self.past_samples.shape[0] != data.shape[0]:\n",
    "            self.past_samples = self.past_samples.expand(data.shape[0], -1, H, W)  # Adjust the batch size\n",
    "\n",
    "        # Concatenate past samples and data along the channel dimension\n",
    "        final_data = torch.cat([self.past_samples, data.float().view(-1, self.out_ch, H, W)], 1)\n",
    "\n",
    "        init_time = T[0].item() * 6\n",
    "        final_time = T[-1].item() * 6\n",
    "        steps_val = final_time - init_time\n",
    "\n",
    "        # Check data shape\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "        if self.pos:\n",
    "            lat_map = self.lat_map.unsqueeze(dim=0) * torch.pi / 180\n",
    "            lon_map = self.lon_map.unsqueeze(dim=0) * torch.pi / 180\n",
    "            pos_rep = torch.cat([lat_map.unsqueeze(dim=0), lon_map.unsqueeze(dim=0), self.const_info], dim=1)\n",
    "            \n",
    "            # Check pos_rep shape\n",
    "            print(f\"pos_rep shape: {pos_rep.shape}\")\n",
    "\n",
    "            self.pos_feat = self.pos_enc(pos_rep).expand(data.shape[0], -1, data.shape[3], data.shape[4])\n",
    "            final_pos_enc = self.pos_feat\n",
    "        else:\n",
    "            self.oro,self.lsm = self.const_info[0,0],self.const_info[0,1]\n",
    "            self.lsm = self.lsm.unsqueeze(dim=0).expand(data.shape[0],-1,data.shape[3],data.shape[4])\n",
    "            self.oro  = F.normalize(self.const_info[0,0]).unsqueeze(dim=0).expand(data.shape[0],-1,data.shape[3],data.shape[4])\n",
    "            self.new_lat_map = self.lat_map.expand(data.shape[0],1,data.shape[3],data.shape[4])*torch.pi/180 # Converting to radians\n",
    "            self.new_lon_map = self.lon_map.expand(data.shape[0],1,data.shape[3],data.shape[4])*torch.pi/180\n",
    "            cos_lat_map,sin_lat_map = torch.cos(self.new_lat_map),torch.sin(self.new_lat_map)\n",
    "            cos_lon_map,sin_lon_map = torch.cos(self.new_lon_map),torch.sin(self.new_lon_map)\n",
    "            pos_feats = torch.cat([cos_lat_map,cos_lon_map,sin_lat_map,sin_lon_map,sin_lat_map*cos_lon_map,sin_lat_map*sin_lon_map],dim=1)\n",
    "            final_pos_enc = torch.cat([self.new_lat_map,self.new_lon_map,pos_feats,self.lsm,self.oro],dim=1)\n",
    "\n",
    "\n",
    "        new_time_steps = torch.linspace(init_time,final_time,steps=int(steps_val)+1).to(data.device)\n",
    "        t = 0.01*new_time_steps.float().to(data.device).flatten().float()\n",
    "        pde_rhs  = lambda t,vs: self.pde(t,vs) # make the ODE forward function\n",
    "        final_result = odeint(pde_rhs,final_data,t,method=self.method,atol=atol,rtol=rtol)\n",
    "        #breakpoint()\n",
    "        s_final = final_result[:,:,-self.out_ch:,:,:].view(len(t),-1,self.out_ch,H,W)\n",
    "\n",
    "        if self.err:\n",
    "            mean,std = self.noise_net_contrib(T,final_pos_enc,s_final[0:len(s_final):6],self.noise_net,H,W)\n",
    "\n",
    "        else:\n",
    "            s_final = s_final[0:len(s_final):6]\n",
    "\n",
    "        return mean,std,s_final[0:len(s_final):6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Climate_encoder_free_uncertain_summary(len(paths_to_data),2,out_types=len(paths_to_data),method=solver,use_att=True,use_err=True,use_pos=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_info_path = [str(cwd) + '/era5_data/constants/constants_5.625deg.nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lev = []\n",
    "min_lev = []\n",
    "levels = [\"z\",\"t\",\"t2m\",\"u10\",\"v10\"]\n",
    "paths_to_data = [str(cwd) + '/era5_data/geopotential_500/*.nc',str(cwd) + '/era5_data/temperature_850/*.nc',str(cwd) + '/era5_data/2m_temperature/*.nc',str(cwd) + '/era5_data/10m_u_component_of_wind/*.nc',str(cwd) + '/era5_data/10m_v_component_of_wind/*.nc']\n",
    "paths_to_data = paths_to_data[0:5]\n",
    "levels = levels[0:5]\n",
    "\n",
    "for idx,data in enumerate(paths_to_data):\n",
    "    Train_data,Val_data,Test_data,time_steps,lat,lon,mean,std,time_stamp = get_train_test_data_batched_regional(data,train_time_scale,val_time_scale,test_time_scale,levels[idx],spectral,\"EastAfrica\")  \n",
    "    max_lev.append(mean)\n",
    "    min_lev.append(std)\n",
    "    if idx==0: \n",
    "        Final_train_data = Train_data\n",
    "        Final_val_data = Val_data\n",
    "        Final_test_data = Test_data\n",
    "    else:\n",
    "        Final_train_data = torch.cat([Final_train_data,Train_data],dim=2)\n",
    "        Final_val_data = torch.cat([Final_val_data,Val_data],dim=2)\n",
    "        Final_test_data = torch.cat([Final_test_data,Test_data],dim=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Input shape for data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (num_years, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(paths_to_data)\u001b[38;5;241m*\u001b[39m(args_scale\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), H, W)  \u001b[38;5;66;03m# Adjusted for the training loop\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\robot\\anaconda3\\envs\\climode_env\\lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[1;32mc:\\Users\\robot\\anaconda3\\envs\\climode_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\robot\\anaconda3\\envs\\climode_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[48], line 185\u001b[0m, in \u001b[0;36mClimate_encoder_free_uncertain_summary.forward\u001b[1;34m(self, T, data, atol, rtol)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, T\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# if T is None:\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m#     T = torch.tensor([0.0, 1.0])  # Example time tensor\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# if data is None:\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;66;03m#     data = torch.zeros(1, self.out_ch, 128, 128)  # Ensure 4D shape\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpast_samples))\n\u001b[1;32m--> 185\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpast_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpast_samples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;66;03m# Debug the shapes\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of self.past_samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpast_samples\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Move model to devicedevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set the dimensions for your input data based on the variables in the training loop\n",
    "num_years = len(range(2006,2016))  # Example number of years (time dimension)\n",
    "args_scale = 0\n",
    "H,W = Train_data.shape[3],Train_data.shape[4]\n",
    "\n",
    "# Input shape for data\n",
    "input_shape = (num_years, 1, len(paths_to_data)*(args_scale+1), H, W)  # Adjusted for the training loop\n",
    "\n",
    "\n",
    "summary(model, input_size=input_shape, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_loader = DataLoader(Final_train_data[2:],batch_size=8,shuffle=False,pin_memory=False)\n",
    "Val_loader = DataLoader(Final_val_data[2:],batch_size=8,shuffle=False,pin_memory=False)\n",
    "Test_loader = DataLoader(Final_test_data[2:],batch_size=8,shuffle=False,pin_memory=False)\n",
    "time_loader = DataLoader(time_steps[2:],batch_size=8,shuffle=False,pin_memory=False)\n",
    "time_idx_steps = torch.tensor([i for i in range(365*4)]).view(-1,1)\n",
    "time_idx = DataLoader(time_idx_steps[2:],batch_size=8,shuffle=False,pin_memory=False)\n",
    "#Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_train,vel_val = load_velocity(['train_10year_2day_mm','val_10year_2day_mm'])\n",
    "const_channels_info,lat_map,lon_map = add_constant_info_region(const_info_path,\"EastAfrica\",H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10, 10, 6, 6]' is invalid for input of size 204800",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mview(num_years,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(paths_to_data)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m),H,W)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(vel_train[entry].shape)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m past_sample \u001b[38;5;241m=\u001b[39m \u001b[43mvel_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_years\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpaths_to_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_param([past_sample,const_channels_info\u001b[38;5;241m.\u001b[39mto(device),lat_map\u001b[38;5;241m.\u001b[39mto(device),lon_map\u001b[38;5;241m.\u001b[39mto(device)])\n\u001b[0;32m     12\u001b[0m t \u001b[38;5;241m=\u001b[39m time_steps\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[10, 10, 6, 6]' is invalid for input of size 204800"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    total_train_loss = 0\n",
    "    val_loss = 0\n",
    "    test_loss = 0\n",
    "    RMSD = []\n",
    "    \n",
    "    for entry,(time_steps,batch) in enumerate(zip(time_loader,Train_loader)):\n",
    "        data = batch[0].to(device).view(num_years,1,len(paths_to_data)*(1),H,W)\n",
    "        # print(vel_train[entry].shape)\n",
    "        past_sample = vel_train[entry].view(num_years,2*len(paths_to_data)*(1),H,W).to(device)\n",
    "        model.update_param([past_sample,const_channels_info.to(device),lat_map.to(device),lon_map.to(device)])\n",
    "        t = time_steps.float().to(device).flatten()\n",
    "        summary(model,(t,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vel_train[entry] shape: torch.Size([10, 2, 5, 32, 64])\n",
      "Total elements: 204800\n",
      "num_years: 10\n",
      "2*len(paths_to_data)*(1): 10\n",
      "H, W: 6, 6\n",
      "Proposed reshape total elements: 3600\n"
     ]
    }
   ],
   "source": [
    "# Print the original tensor's shape and total elements\n",
    "print(f\"Original vel_train[entry] shape: {vel_train[entry].shape}\")\n",
    "print(f\"Total elements: {vel_train[entry].numel()}\")\n",
    "\n",
    "# Print the dimensions you're trying to use\n",
    "print(f\"num_years: {num_years}\")\n",
    "print(f\"2*len(paths_to_data)*(1): {2*len(paths_to_data)*(1)}\")\n",
    "print(f\"H, W: {H}, {W}\")\n",
    "\n",
    "# Calculate the total elements in the proposed reshape\n",
    "proposed_reshape_elements = num_years * (2*len(paths_to_data)*(1)) * H * W\n",
    "print(f\"Proposed reshape total elements: {proposed_reshape_elements}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate_encoder_free_uncertain_summary(\n",
      "  (vel_f): Climate_ResNet_2D(\n",
      "    (layer_cnn): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (2): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (3): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (4): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (2): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(64, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (activation_cnn): ModuleList()\n",
      "  )\n",
      "  (vel_att): Self_attn_conv(\n",
      "    (query): Sequential(\n",
      "      (0): boundarypad()\n",
      "      (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (2): LeakyReLU(negative_slope=0.3)\n",
      "      (3): boundarypad()\n",
      "      (4): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): LeakyReLU(negative_slope=0.3)\n",
      "      (6): boundarypad()\n",
      "      (7): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (key): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (1): LeakyReLU(negative_slope=0.3)\n",
      "      (2): Conv2d(32, 8, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (3): LeakyReLU(negative_slope=0.3)\n",
      "      (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (value): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (1): LeakyReLU(negative_slope=0.3)\n",
      "      (2): Conv2d(32, 10, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (3): LeakyReLU(negative_slope=0.3)\n",
      "      (4): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (post_map): Sequential(\n",
      "      (0): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (noise_net): Climate_ResNet_2D(\n",
      "    (layer_cnn): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(43, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Conv2d(43, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (2): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(64, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "        (1): ResidualBlock(\n",
      "          (activation): LeakyReLU(negative_slope=0.3)\n",
      "          (conv1): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "          (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (shortcut): Identity()\n",
      "          (norm1): Identity()\n",
      "          (norm2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (activation_cnn): ModuleList()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climode_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
