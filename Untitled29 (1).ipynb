{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0IzUl45o65xd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import List, Optional, Tuple, Union\n",
        "import torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lws0AwMgpaAr"
      },
      "outputs": [],
      "source": [
        "class boundarypad(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.pad(F.pad(input,(0,0,1,1),'reflect'),(1,1,0,0),'circular')\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        activation: str = \"gelu\",\n",
        "        norm: bool = False,\n",
        "        n_groups: int = 1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.activation = nn.LeakyReLU(0.3)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=0)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.drop = nn.Dropout(p=0.1)\n",
        "        # If the number of input channels is not equal to the number of output channels we have to\n",
        "        # project the shortcut connection\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1))\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "        if norm:\n",
        "            self.norm1 = nn.GroupNorm(n_groups, in_channels)\n",
        "            self.norm2 = nn.GroupNorm(n_groups, out_channels)\n",
        "        else:\n",
        "            self.norm1 = nn.Identity()\n",
        "            self.norm2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        # First convolution layer\n",
        "        x_mod = F.pad(F.pad(x,(0,0,1,1),'reflect'),(1,1,0,0),'circular')\n",
        "        h = self.activation(self.bn1(self.conv1(self.norm1(x_mod))))\n",
        "        # Second convolution layer\n",
        "        h = F.pad(F.pad(h,(0,0,1,1),'reflect'),(1,1,0,0),'circular')\n",
        "        h = self.activation(self.bn2(self.conv2(self.norm2(h))))\n",
        "        h = self.drop(h)\n",
        "        # Add the shortcut connection and return\n",
        "        return h + self.shortcut(x)\n",
        "\n",
        "\n",
        "class Self_attn_conv_reg(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels,out_channels):\n",
        "        super(Self_attn_conv_reg, self).__init__()\n",
        "        self.query = self._conv(in_channels,in_channels//8,stride=1)\n",
        "        self.key = self.key_conv(in_channels,in_channels//8,stride=2)\n",
        "        self.value = self.key_conv(in_channels,out_channels,stride=2)\n",
        "        self.post_map = nn.Sequential(nn.Conv2d(out_channels,out_channels,kernel_size=(1,1),stride=1,padding=0))\n",
        "        self.out_ch = out_channels\n",
        "\n",
        "    def _conv(self,n_in,n_out,stride):\n",
        "        return nn.Sequential(boundarypad(),nn.Conv2d(n_in,n_in//2,kernel_size=(3,3),stride=stride,padding=0),nn.LeakyReLU(0.3),boundarypad(),nn.Conv2d(n_in//2,n_out,kernel_size=(3,3),stride=stride,padding=0),nn.LeakyReLU(0.3),boundarypad(),nn.Conv2d(n_out,n_out,kernel_size=(3,3),stride=stride,padding=0))\n",
        "\n",
        "    def key_conv(self,n_in,n_out,stride):\n",
        "        return nn.Sequential(boundarypad(),nn.Conv2d(n_in,n_in//2,kernel_size=(3,3),stride=stride,padding=0),nn.LeakyReLU(0.3),boundarypad(),nn.Conv2d(n_in//2,n_out,kernel_size=(3,3),stride=stride,padding=0),nn.LeakyReLU(0.3),boundarypad(),nn.Conv2d(n_out,n_out,kernel_size=(3,3),stride=1,padding=0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.size()\n",
        "        x = x.float()\n",
        "        q,k,v = self.query(x).flatten(-2,-1),self.key(x).flatten(-2,-1),self.value(x).flatten(-2,-1)\n",
        "        beta = F.softmax(torch.bmm(q.transpose(1,2), k), dim=1)\n",
        "        o = torch.bmm(v, beta.transpose(1,2))\n",
        "        o = self.post_map(o.view(-1,self.out_ch,size[-2],size[-1]).contiguous())\n",
        "        return o\n",
        "\n",
        "\n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        \"\"\"\n",
        "        Squeeze-and-Excitation Layer\n",
        "\n",
        "        Args:\n",
        "            channel (int): Number of input channels\n",
        "            reduction (int): Reduction ratio for channel compression\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of SE Layer\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input feature map\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Channel-wise recalibrated feature map\n",
        "        \"\"\"\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class SEResNetBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        activation: str = \"gelu\",\n",
        "        norm: bool = False,\n",
        "        n_groups: int = 1,\n",
        "        reduction: int = 16\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Squeeze-and-Excitation ResNet Block\n",
        "\n",
        "        Args:\n",
        "            in_channels (int): Number of input channels\n",
        "            out_channels (int): Number of output channels\n",
        "            activation (str): Activation function type\n",
        "            norm (bool): Whether to use group normalization\n",
        "            n_groups (int): Number of groups for group normalization\n",
        "            reduction (int): Reduction ratio for SE layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.activation = nn.LeakyReLU(0.3)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=0)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.se_layer = SELayer(out_channels, reduction)\n",
        "\n",
        "        self.drop = nn.Dropout(p=0.2)\n",
        "\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1)),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "                )\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "        if norm:\n",
        "            self.norm1 = nn.GroupNorm(n_groups, in_channels)\n",
        "            self.norm2 = nn.GroupNorm(n_groups, out_channels)\n",
        "        else:\n",
        "            self.norm1 = nn.Identity()\n",
        "            self.norm2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Forward pass of SE-ResNet Block\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after SE-ResNet block processing\n",
        "        \"\"\"\n",
        "        x_mod = F.pad(F.pad(x, (0,0,1,1), 'reflect'), (1,1,0,0), 'circular')\n",
        "        h = self.activation(self.bn1(self.conv1(self.norm1(x_mod))))\n",
        "\n",
        "        h = F.pad(F.pad(h, (0,0,1,1), 'reflect'), (1,1,0,0), 'circular')\n",
        "        h = self.activation(self.bn2(self.conv2(self.norm2(h))))\n",
        "\n",
        "        h = self.se_layer(h)\n",
        "\n",
        "        h = self.drop(h)\n",
        "\n",
        "        return h + self.shortcut(x)\n",
        "\n",
        "\n",
        "\n",
        "class Self_attn_conv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels,out_channels):\n",
        "        super(Self_attn_conv, self).__init__()\n",
        "        self.query = self._conv(in_channels,in_channels//8,stride=1)\n",
        "        self.key = self.key_conv(in_channels,in_channels//8,stride=2)\n",
        "        self.value = self.key_conv(in_channels,out_channels,stride=2)\n",
        "        self.post_map = nn.Sequential(nn.Conv2d(out_channels,out_channels,kernel_size=(1,1),stride=1,padding=0))\n",
        "        self.out_ch = out_channels\n",
        "\n",
        "    def _conv(self,n_in,n_out,stride):\n",
        "        return nn.Sequential(boundarypad(),nn.Conv2d(n_in,n_in//2,kernel_size=(3,3),stride=stride,padding=0),nn.LeakyReLU(0.3),boundarypad(),nn.Conv2d(n_in//2,n_out,kernel_size=(3,3),stride=stride,padding=0),nn.LeakyReLU(0.3),boundarypad(),nn.Conv2d(n_out,n_out,kernel_size=(3,3),stride=stride,padding=0))\n",
        "\n",
        "    def key_conv(self,n_in,n_out,stride):\n",
        "        return nn.Sequential(nn.Conv2d(n_in,n_in//2,kernel_size=(3,3),stride=stride,padding=0),nn.LeakyReLU(0.3),nn.Conv2d(n_in//2,n_out,kernel_size=(3,3),stride=stride,padding=0),nn.LeakyReLU(0.3),nn.Conv2d(n_out,n_out,kernel_size=(3,3),stride=1,padding=0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.size()\n",
        "        x = x.float()\n",
        "        q,k,v = self.query(x).flatten(-2,-1),self.key(x).flatten(-2,-1),self.value(x).flatten(-2,-1)\n",
        "        beta = F.softmax(torch.bmm(q.transpose(1,2), k), dim=1)\n",
        "        o = torch.bmm(v, beta.transpose(1,2))\n",
        "        o = self.post_map(o.view(-1,self.out_ch,size[-2],size[-1]).contiguous())\n",
        "        return o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GX8VTgujpUSH"
      },
      "outputs": [],
      "source": [
        "class Climate_SEResNet_2D(nn.Module):\n",
        "\n",
        "    def __init__(self,num_channels,layers,hidden_size):\n",
        "        super().__init__()\n",
        "        layers_cnn = []\n",
        "        activation_fns = []\n",
        "        self.block = SEResNetBlock\n",
        "        self.inplanes = num_channels\n",
        "\n",
        "        for idx in range(len(layers)):\n",
        "            if idx ==0:\n",
        "               layers_cnn.append(self.make_layer(self.block,num_channels,hidden_size[idx],layers[idx]))\n",
        "            else:\n",
        "                layers_cnn.append(self.make_layer(self.block,hidden_size[idx-1],hidden_size[idx],layers[idx]))\n",
        "\n",
        "        self.layer_cnn = nn.ModuleList(layers_cnn)\n",
        "        self.activation_cnn = nn.ModuleList(activation_fns)\n",
        "\n",
        "    def make_layer(self,block,in_channels,out_channels,reps):\n",
        "        layers = []\n",
        "        layers.append(block(in_channels,out_channels))\n",
        "        self.inplanes = out_channels\n",
        "        for i in range(1, reps):\n",
        "              layers.append(block(out_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self,data):\n",
        "        dx_final = data.float()\n",
        "        for l,layer in enumerate(self.layer_cnn):\n",
        "            dx_final = layer(dx_final)\n",
        "\n",
        "\n",
        "        return dx_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VivI6aOXhpNo"
      },
      "outputs": [],
      "source": [
        "class ClimODE_uncertain_region_SEResNet(nn.Module):\n",
        "\n",
        "    def __init__(self,num_channels,const_channels,out_types,method,use_att,use_err,use_pos):\n",
        "        super().__init__()\n",
        "        self.layers = [5,3,2]\n",
        "        self.hidden = [128,64,2*out_types]\n",
        "        input_channels = 30 + out_types*int(use_pos) + 34*(1-int(use_pos))\n",
        "        self.vel_f = Climate_SEResNet_2D(input_channels,self.layers,self.hidden)\n",
        "\n",
        "        if use_att:\n",
        "            self.vel_att = Self_attn_conv_reg(input_channels,2*out_types)\n",
        "            self.gamma = nn.Parameter(torch.tensor([0.1]))\n",
        "\n",
        "        self.scales = num_channels\n",
        "        self.const_channel = const_channels\n",
        "\n",
        "        self.out_ch = out_types\n",
        "        self.past_samples = 0\n",
        "        self.const_info = 0\n",
        "        self.lat_map = 0\n",
        "        self.lon_map = 0\n",
        "        self.elev = 0\n",
        "        self.pos_emb = 0\n",
        "        self.elev_info_grad_x = 0\n",
        "        self.elev_info_grad_y = 0\n",
        "        self.method = method\n",
        "        err_in =  9 + out_types*int(use_pos) + 34*(1-int(use_pos))\n",
        "        if use_err: self.noise_net = Climate_SEResNet_2D(err_in,[3,2,2],[128,64,2*out_types])\n",
        "        if use_pos: self.pos_enc = Climate_SEResNet_2D(4,[2,1,1],[32,16,out_types])\n",
        "        self.att = use_att\n",
        "        self.err = use_err\n",
        "        self.pos = use_pos\n",
        "        self.pos_feat = 0\n",
        "        self.lsm =0\n",
        "        self.oro =0\n",
        "\n",
        "    def update_param(self, params):\n",
        "        self.past_samples = params[0]\n",
        "        self.const_info = params[1]\n",
        "        self.lat_map = params[2]\n",
        "        self.lon_map = params[3]\n",
        "\n",
        "    def pde(self,t,vs):\n",
        "\n",
        "        ds = vs[:,-self.out_ch:,:,:].float().view(-1,self.out_ch,vs.shape[2],vs.shape[3]).float()\n",
        "        v = vs[:,:2*self.out_ch,:,:].float().view(-1,2*self.out_ch,vs.shape[2],vs.shape[3]).float()\n",
        "        t_emb = ((t*100)%24).view(1,1,1,1).expand(ds.shape[0],1,ds.shape[2],ds.shape[3])\n",
        "        sin_t_emb = torch.sin(torch.pi*t_emb/12 - torch.pi/2)\n",
        "        cos_t_emb = torch.cos(torch.pi*t_emb/12 - torch.pi/2)\n",
        "\n",
        "        sin_seas_emb = torch.sin(torch.pi*t_emb/(12*365) - torch.pi/2)\n",
        "        cos_seas_emb = torch.cos(torch.pi*t_emb/(12*365) - torch.pi/2)\n",
        "\n",
        "        day_emb = torch.cat([sin_t_emb,cos_t_emb],dim=1)\n",
        "        seas_emb = torch.cat([sin_seas_emb,cos_seas_emb],dim=1)\n",
        "\n",
        "        ds_grad_x = torch.gradient(ds,dim=3)[0]\n",
        "        ds_grad_y = torch.gradient(ds,dim=2)[0]\n",
        "        nabla_u = torch.cat([ds_grad_x,ds_grad_y],dim=1)\n",
        "\n",
        "        if self.pos:\n",
        "            comb_rep = torch.cat([t_emb/24,day_emb,seas_emb,nabla_u,v,ds,self.pos_feat],dim=1)\n",
        "        else:\n",
        "            cos_lat_map,sin_lat_map = torch.cos(self.new_lat_map),torch.sin(self.new_lat_map)\n",
        "            cos_lon_map,sin_lon_map = torch.cos(self.new_lon_map),torch.sin(self.new_lon_map)\n",
        "            t_cyc_emb = torch.cat([day_emb,seas_emb],dim=1)\n",
        "            pos_feats = torch.cat([cos_lat_map,cos_lon_map,sin_lat_map,sin_lon_map,sin_lat_map*cos_lon_map,sin_lat_map*sin_lon_map],dim=1)\n",
        "            pos_time_ft = self.get_time_pos_embedding(t_cyc_emb,pos_feats)\n",
        "            comb_rep = torch.cat([t_emb/24,day_emb,seas_emb,nabla_u,v,ds,self.new_lat_map,self.new_lon_map,self.lsm,self.oro,pos_feats,pos_time_ft],dim=1)\n",
        "\n",
        "        if self.att: dv = self.vel_f(comb_rep) + self.gamma*self.vel_att(comb_rep)\n",
        "        else: dv = self.vel_f(comb_rep)\n",
        "        v_x = v[:,:self.out_ch,:,:].float().view(-1,self.out_ch,vs.shape[2],vs.shape[3]).float()\n",
        "        v_y = v[:,-self.out_ch:,:,:].float().view(-1,self.out_ch,vs.shape[2],vs.shape[3]).float()\n",
        "\n",
        "        adv1 = v_x*ds_grad_x + v_y*ds_grad_y\n",
        "        adv2 = ds*(torch.gradient(v_x,dim=3)[0] + torch.gradient(v_y,dim=2)[0] )\n",
        "\n",
        "        ds = adv1 + adv2\n",
        "        dvs = torch.cat([dv,ds],1)\n",
        "        return dvs\n",
        "\n",
        "\n",
        "    def get_time_pos_embedding(self,time_feats,pos_feats):\n",
        "        for idx in range(time_feats.shape[1]):\n",
        "            tf = time_feats[:,idx].unsqueeze(dim=1)*pos_feats\n",
        "            if idx == 0:\n",
        "                final_out = tf\n",
        "            else:\n",
        "                final_out = torch.cat([final_out,tf],dim=1)\n",
        "\n",
        "        return final_out\n",
        "\n",
        "    def noise_net_contrib(self,t,pos_enc,s_final,noise_net,H,W):\n",
        "\n",
        "        t_emb = (t%24).view(-1,1,1,1,1)\n",
        "        sin_t_emb = torch.sin(torch.pi*t_emb/12 - torch.pi/2).expand(len(s_final),s_final.shape[1],1,H,W)\n",
        "        cos_t_emb = torch.cos(torch.pi*t_emb/12 - torch.pi/2).expand(len(s_final),s_final.shape[1],1,H,W)\n",
        "\n",
        "        sin_seas_emb = torch.sin(torch.pi*t_emb/(12*365)- torch.pi/2).expand(len(s_final),s_final.shape[1],1,H,W)\n",
        "        cos_seas_emb = torch.cos(torch.pi*t_emb/(12*365)- torch.pi/2).expand(len(s_final),s_final.shape[1],1,H,W)\n",
        "\n",
        "        pos_enc = pos_enc.expand(len(s_final),s_final.shape[1],-1,H,W).flatten(start_dim=0,end_dim=1)\n",
        "        t_cyc_emb = torch.cat([sin_t_emb,cos_t_emb,sin_seas_emb,cos_seas_emb],dim=2).flatten(start_dim=0,end_dim=1)\n",
        "\n",
        "        pos_time_ft = self.get_time_pos_embedding(t_cyc_emb,pos_enc[:,2:-2])\n",
        "\n",
        "        comb_rep = torch.cat([t_cyc_emb,s_final.flatten(start_dim=0,end_dim=1),pos_enc,pos_time_ft],dim=1)\n",
        "\n",
        "        final_out = noise_net(comb_rep).view(len(t),-1,2*self.out_ch,H,W)\n",
        "\n",
        "        mean = s_final + final_out[:,:,:self.out_ch]\n",
        "        std = nn.Softplus()(final_out[:,:,self.out_ch:])\n",
        "\n",
        "        return mean,std\n",
        "\n",
        "\n",
        "    def forward(self,T,data,atol=0.1,rtol=0.1):\n",
        "        H,W = self.past_samples.shape[2],self.past_samples.shape[3]\n",
        "        final_data = torch.cat([self.past_samples ,data.float().view(-1,self.out_ch,H,W)],1)\n",
        "        init_time = T[0].item()*6\n",
        "        final_time = T[-1].item()*6\n",
        "        steps_val = final_time - init_time\n",
        "\n",
        "        #breakpoint()\n",
        "\n",
        "        if self.pos:\n",
        "            lat_map = self.lat_map.unsqueeze(dim=0)*torch.pi/180\n",
        "            lon_map = self.lon_map.unsqueeze(dim=0)*torch.pi/180\n",
        "            pos_rep = torch.cat([lat_map.unsqueeze(dim=0),lon_map.unsqueeze(dim=0),self.const_info],dim=1)\n",
        "            self.pos_feat = self.pos_enc(pos_rep).expand(data.shape[0],-1,data.shape[3],data.shape[4])\n",
        "            final_pos_enc = self.pos_feat\n",
        "\n",
        "        else:\n",
        "            self.oro,self.lsm = self.const_info[0,0],self.const_info[0,1]\n",
        "            self.lsm = self.lsm.unsqueeze(dim=0).expand(data.shape[0],-1,data.shape[3],data.shape[4])\n",
        "            self.oro  = F.normalize(self.const_info[0,0]).unsqueeze(dim=0).expand(data.shape[0],-1,data.shape[3],data.shape[4])\n",
        "            self.new_lat_map = self.lat_map.expand(data.shape[0],1,data.shape[3],data.shape[4])*torch.pi/180 # Converting to radians\n",
        "            self.new_lon_map = self.lon_map.expand(data.shape[0],1,data.shape[3],data.shape[4])*torch.pi/180\n",
        "            cos_lat_map,sin_lat_map = torch.cos(self.new_lat_map),torch.sin(self.new_lat_map)\n",
        "            cos_lon_map,sin_lon_map = torch.cos(self.new_lon_map),torch.sin(self.new_lon_map)\n",
        "            pos_feats = torch.cat([cos_lat_map,cos_lon_map,sin_lat_map,sin_lon_map,sin_lat_map*cos_lon_map,sin_lat_map*sin_lon_map],dim=1)\n",
        "            final_pos_enc = torch.cat([self.new_lat_map,self.new_lon_map,pos_feats,self.lsm,self.oro],dim=1)\n",
        "\n",
        "\n",
        "        new_time_steps = torch.linspace(init_time,final_time,steps=int(steps_val)+1).to(data.device)\n",
        "        t = 0.01*new_time_steps.float().to(data.device).flatten().float()\n",
        "        pde_rhs  = lambda t,vs: self.pde(t,vs) # make the ODE forward function\n",
        "        final_result = odeint(pde_rhs,final_data,t,method=self.method,atol=atol,rtol=rtol)\n",
        "        s_final = final_result[:,:,-self.out_ch:,:,:].view(len(t),-1,self.out_ch,H,W)\n",
        "\n",
        "        if self.err:\n",
        "            mean,std = self.noise_net_contrib(T,final_pos_enc,s_final[0:len(s_final):6],self.noise_net,H,W)\n",
        "\n",
        "        else:\n",
        "            s_final = s_final[0:len(s_final):6]\n",
        "\n",
        "        return mean,std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHgyYLCd7CBy",
        "outputId": "16196b04-50a5-43ac-95d6-12840dd632bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
          ]
        }
      ],
      "source": [
        "model = ClimODE_uncertain_region_SEResNet(\n",
        "    num_channels=3,           # Example number of channels\n",
        "    const_channels=1,         # Example constant channels\n",
        "    out_types=2,              # Example output types\n",
        "    method=\"dopri5\",          # Example ODE solving method\n",
        "    use_att=True,             # Example usage of attention\n",
        "    use_err=True,             # Example usage of error estimation\n",
        "    use_pos=True              # Example usage of positional encoding\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKNHZWUc-x9H",
        "outputId": "60bd7b17-bf3f-4e74-8482-b2a8dc9098bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClimODE_uncertain_region_SEResNet(\n",
            "  (vel_f): Climate_SEResNet_2D(\n",
            "    (layer_cnn): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (1): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (2): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (3): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (4): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=4, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=4, out_features=64, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (1): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=4, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=4, out_features=64, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (2): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=4, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=4, out_features=64, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=4, out_features=0, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=0, out_features=4, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (1): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=4, out_features=0, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=0, out_features=4, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (activation_cnn): ModuleList()\n",
            "  )\n",
            "  (vel_att): Self_attn_conv_reg(\n",
            "    (query): Sequential(\n",
            "      (0): boundarypad()\n",
            "      (1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (2): LeakyReLU(negative_slope=0.3)\n",
            "      (3): boundarypad()\n",
            "      (4): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (5): LeakyReLU(negative_slope=0.3)\n",
            "      (6): boundarypad()\n",
            "      (7): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "    )\n",
            "    (key): Sequential(\n",
            "      (0): boundarypad()\n",
            "      (1): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (2): LeakyReLU(negative_slope=0.3)\n",
            "      (3): boundarypad()\n",
            "      (4): Conv2d(16, 4, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (5): LeakyReLU(negative_slope=0.3)\n",
            "      (6): boundarypad()\n",
            "      (7): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "    )\n",
            "    (value): Sequential(\n",
            "      (0): boundarypad()\n",
            "      (1): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (2): LeakyReLU(negative_slope=0.3)\n",
            "      (3): boundarypad()\n",
            "      (4): Conv2d(16, 4, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (5): LeakyReLU(negative_slope=0.3)\n",
            "      (6): boundarypad()\n",
            "      (7): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "    )\n",
            "    (post_map): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (noise_net): Climate_SEResNet_2D(\n",
            "    (layer_cnn): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(11, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(11, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (1): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (2): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=128, out_features=8, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=8, out_features=128, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=4, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=4, out_features=64, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (1): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=64, out_features=4, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=4, out_features=64, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=4, out_features=0, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=0, out_features=4, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (1): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=4, out_features=0, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=0, out_features=4, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (activation_cnn): ModuleList()\n",
            "  )\n",
            "  (pos_enc): Climate_SEResNet_2D(\n",
            "    (layer_cnn): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=32, out_features=2, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=2, out_features=32, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "        (1): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=32, out_features=2, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=2, out_features=32, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Identity()\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=16, out_features=1, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=1, out_features=16, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): SEResNetBlock(\n",
            "          (activation): LeakyReLU(negative_slope=0.3)\n",
            "          (conv1): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1))\n",
            "          (bn2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (se_layer): SELayer(\n",
            "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc): Sequential(\n",
            "              (0): Linear(in_features=2, out_features=0, bias=False)\n",
            "              (1): ReLU(inplace=True)\n",
            "              (2): Linear(in_features=0, out_features=2, bias=False)\n",
            "              (3): Sigmoid()\n",
            "            )\n",
            "          )\n",
            "          (drop): Dropout(p=0.2, inplace=False)\n",
            "          (shortcut): Sequential(\n",
            "            (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (norm1): Identity()\n",
            "          (norm2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (activation_cnn): ModuleList()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VglUXy1gdtkd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}